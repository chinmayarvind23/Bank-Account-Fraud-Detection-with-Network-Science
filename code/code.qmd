---
title: "Bank Account Fraud Detection - COSC 421 Course Project"
output-file: index.html
format:
  html:
    theme: flatly
    css: styles/styles.css
    toc: true
    toc-location: left
---

#### Team Members: Chinmay Arvind, Dmitry Kostyukov, Jerry Fan, Rylan Millar

# Imports & Libraries Setup

```{r}
renv::snapshot()
source("../renv/activate.R")
renv::init()
renv::status()

required_packages <- c("rmarkdown", "tidyverse", "visNetwork", "AzureStor")

for (pkg in required_packages) {
  if (!requireNamespace(pkg, quietly = TRUE)) {
    install.packages(pkg, repos = "https://cloud.r-project.org")
  }
}
install.packages(c('rmarkdown', 'tidyverse', 'visNetwork', 'AzureStor'))
install.packages(c('readr', 'dplyr', 'httr'))
install.packages("igraph")
install.packages("dotenv")
install.packages("tidyverse")
install.packages("purrr")
renv::snapshot()
library(rmarkdown)
library(tidyverse)
library(visNetwork)
library(igraph)
library(AzureStor)
library(readr)
library(dplyr)
library(httr)
library(dotenv)
library(tidyverse)
library(purrr)
```

# Data loading

```{r}
# load_dot_env(file = "/Users/chinmayarvind/Documents/UBC/UBC Coursework/COSC 421/Course Project/Bank-Account-Fraud-Detection-with-Network-Science/.env")
#storage_container_url <- Sys.getenv("AZURE_STORAGE_SAS_URL")
#if (storage_container_url == "") {
#  stop("SAS URL not found. Please set the 'AZURE_STORAGE_SAS_URL' environment variable.")
#}

# Change this path to the path from where you have downloaded the Base.csv file to
bankfraud_data <- read_csv("/Users/chinmayarvind/Documents/UBC/UBC Coursework/COSC 421/Course Project/Bank-Account-Fraud-Detection-with-Network-Science/data/Base.csv")
bankfraud_data
```

# Data cleaning, and PCA

```{r}
colSums(is.na(bankfraud_data))
```

No missing values, so we can proceed with the rest of the data cleaning.

```{r}
summary(bankfraud_data)
str(bankfraud_data)
```

```{r}
bankfraud_data <- bankfraud_data[!duplicated(bankfraud_data), ]
bankfraud_data
```

No duplicates identified, so we can proceed with PCA and feature engineering. Removing the Device OS columns and the source columns as they are not helpful predictors in predicting bank fraud. The character data type columns are converted to numeric types for making PCA possible.

```{r}
bankfraud_data <- bankfraud_data[, -c(26, 28)]
bankfraud_data <- bankfraud_data %>% mutate(across(where(is.character), ~ as.numeric(as.factor(.))))
bankfraud_data
```

Printing a summary of the dataset so far.

```{r}
str(bankfraud_data)
```

Removing columns with 0 variance in them, as they will not contribute to predicting fraud in any way.

```{r}
not_required_cols <- sapply(bankfraud_data, function(x) var(x, na.rm = TRUE) == 0)
print("Columns with zero variance:")
print(names(bankfraud_data)[not_required_cols])
bankfraud_data <- bankfraud_data[, !not_required_cols]
print("Remaining columns after removing zero variance columns:")
print(names(bankfraud_data))
```

Printing a summary of the PCA performed after scaling the data, which shows the number of principal components that explain x% of the variance in the dataset along with charts that indicate the same.

```{r}
pcaCharts <- function(x) {
    x.var <- x$sdev ^ 2
    x.pvar <- x.var/sum(x.var)
    print("proportions of variance:")
    print(x.pvar)
    
    par(mfrow=c(2,2))
    plot(x.pvar,xlab="Principal component", ylab="Proportion of variance explained", ylim=c(0,1), type='b')
    plot(cumsum(x.pvar),xlab="Principal component", ylab="Cumulative Proportion of variance explained", ylim=c(0,1), type='b')
    screeplot(x)
    screeplot(x,type="l")
    par(mfrow=c(1,1))
}

bankfraud_data_pca <- prcomp(scale(bankfraud_data),center = TRUE)
print(bankfraud_data_pca)
summary(bankfraud_data_pca)
pcaCharts(bankfraud_data_pca)
```

Printing the covariance and correlation matrices of the data.

```{r}
covariancematrix <- cov(bankfraud_data)
covariancematrix

corellationmatrix = cor(bankfraud_data)
corellationmatrix
```

Shows the data points based on their fraud classification status on a biplot showing how much each feature contributes to the first 2 principal components.

```{r}
install.packages("ggplot2")
install.packages("ggfortify")
library(ggplot2)
library(ggfortify)
autoplot(bankfraud_data_pca, data = bankfraud_data, colour = 'fraud_bool', loadings = TRUE, loadings.label = TRUE, loadings.label.size = 3)
```

Setting an absolute threshold of 0.5 for selecting the impact of features on the principal components.

```{r}
pca_loadings <- bankfraud_data_pca$rotation[, 1:24]
threshold <- 0.5
selected_features <- unique(c(
  rownames(pca_loadings)[abs(pca_loadings[,1]) > threshold],
  rownames(pca_loadings)[abs(pca_loadings[,2]) > threshold],
  rownames(pca_loadings)[abs(pca_loadings[,3]) > threshold],
  rownames(pca_loadings)[abs(pca_loadings[,4]) > threshold],
  rownames(pca_loadings)[abs(pca_loadings[,5]) > threshold],
  rownames(pca_loadings)[abs(pca_loadings[,6]) > threshold],
  rownames(pca_loadings)[abs(pca_loadings[,7]) > threshold],
  rownames(pca_loadings)[abs(pca_loadings[,8]) > threshold],
  rownames(pca_loadings)[abs(pca_loadings[,9]) > threshold],
  rownames(pca_loadings)[abs(pca_loadings[,10]) > threshold],
  rownames(pca_loadings)[abs(pca_loadings[,11]) > threshold],
  rownames(pca_loadings)[abs(pca_loadings[,12]) > threshold],
  rownames(pca_loadings)[abs(pca_loadings[,13]) > threshold],
  rownames(pca_loadings)[abs(pca_loadings[,14]) > threshold],
  rownames(pca_loadings)[abs(pca_loadings[,15]) > threshold],
  rownames(pca_loadings)[abs(pca_loadings[,16]) > threshold],
  rownames(pca_loadings)[abs(pca_loadings[,17]) > threshold],
  rownames(pca_loadings)[abs(pca_loadings[,18]) > threshold],
  rownames(pca_loadings)[abs(pca_loadings[,19]) > threshold],
  rownames(pca_loadings)[abs(pca_loadings[,20]) > threshold],
  rownames(pca_loadings)[abs(pca_loadings[,21]) > threshold],
  rownames(pca_loadings)[abs(pca_loadings[,22]) > threshold],
  rownames(pca_loadings)[abs(pca_loadings[,23]) > threshold],
  rownames(pca_loadings)[abs(pca_loadings[,24]) > threshold]))

print(selected_features)
```

Prting the rotation matrix of the PCA that indicates the magnitude and direction of contribution of a feature to various principal components.

```{r}
bankfraud_data_pca$rotation
```

# Final dataset with most relevant features for predicting fraud.

Rows with missing (-1) values in the bank_months_count and current_address_months_count are removed as these are considered missing values. The days_since_request column is removed due to having unreliable data - the data is supposed to range from 0 to 78 days, however the majority of the entries are less than one. The negative values from velocity_6h are also removed as they are uninterpretable in the context of the velocity of applications.

```{r}
bankfraud_data <- bankfraud_data[, c(selected_features)]
bankfraud_data %>% relocate(fraud_bool)
bankfraud_data

str(bankfraud_data)

# Checking for inconsistent values
range(bankfraud_data$bank_months_count)
range(bankfraud_data$current_address_months_count)
range(bankfraud_data$days_since_request)

# Removing -1 values
bankfraud_data = bankfraud_data[bankfraud_data$bank_months_count != -1, ]
bankfraud_data = bankfraud_data[bankfraud_data$current_address_months_count != -1, ]

# Dropping days_since_request column
bankfraud_data = subset(bankfraud_data, select = -c(days_since_request))

# Removing negative values from velocity_6h
bankfraud_data = bankfraud_data[bankfraud_data$velocity_6h >= 0, ]
nrow(bankfraud_data)

```

# Feature Engineering

Checking data ranges, and enumerating records in the CSV file as nodes with Node IDs. We have taken a sample here to check if the graph creation is feasible before generating the graph with all of the nodes in it.

```{r}
str(bankfraud_data)

# Checking ranges
range(bankfraud_data$payment_type)
range(bankfraud_data$bank_months_count)
range(bankfraud_data$bank_branch_count_8w)
range(bankfraud_data$zip_count_4w)
range(bankfraud_data$name_email_similarity)
range(bankfraud_data$bank_months_count)
range(bankfraud_data$housing_status)
range(bankfraud_data$velocity_6h)
range(bankfraud_data$current_address_months_count)

# Adding node_id column to identify vertices
bankfraud_data$node_id = seq.int(nrow(bankfraud_data))
bankfraud_data = bankfraud_data %>% relocate(node_id)

# Creating Bins for bank_branch_count_8w, zip_count_4w, name_email_similarity, bank_months_count, velocity_6h, current_address_months_count
bin_count = 5
binned_bankfraud_data = bankfraud_data
cols_to_bin = c("bank_branch_count_8w", "zip_count_4w", "name_email_similarity", "bank_months_count", "velocity_6h", "current_address_months_count")
binned_bankfraud_data[cols_to_bin] = data.frame(lapply(binned_bankfraud_data[cols_to_bin], function(x) cut(x, breaks = bin_count, labels=FALSE)))
str(binned_bankfraud_data)

# Creating binary combination column
binary_columns = c("keep_alive_session", "foreign_request", "email_is_free", "fraud_bool", "phone_home_valid")
binned_bankfraud_data$binary_combination_value = apply(binned_bankfraud_data[binary_columns], 1, function(x) {paste(as.character(x), collapse = "")})
str(binned_bankfraud_data)

# Creating sample
sample_size = 50
data_sample = sample_n(binned_bankfraud_data, sample_size)
str(data_sample)

# Creating edge list
edges_list <- expand.grid(row_id_1 = seq_len(nrow(data_sample)), row_id_2 = seq_len(nrow(data_sample))) %>%
  filter(row_id_1 < row_id_2) %>%
  rowwise() %>%
  mutate(
    edge_type = list(names(data_sample)[-c(1,3:6,13)][
      sapply(names(data_sample)[-c(1,3:6,13)], function(col) {
        data_sample[[col]][row_id_1] == data_sample[[col]][row_id_2]
      })
    ])
  ) %>%
  filter(length(edge_type) > 0) %>%
  unnest(edge_type) %>%
  ungroup() %>%
  mutate(
    node_id_1 = data_sample$node_id[row_id_1],
    node_id_2 = data_sample$node_id[row_id_2]
  ) %>%
  select(node_id_1, node_id_2, edge_type)
print(edges_list)
nrow(edges_list)
unique(edges_list$edge_type)
# Plotting the Data
graph <- graph_from_data_frame(d = edges_list, vertices = data_sample, directed = FALSE)
edge_type_colors <- c("payment_type" = "green", "bank_branch_count_8w" = "blue", "name_email_similarity" = "yellow",
                       "zip_count_4w" = "cyan", "velocity_6h" = "blueviolet", "current_address_months_count" = "gold4",
                       "bank_months_count" = "darkseagreen1", "housing_status" = "darkorange1", "binary_combination_value" = "black")
E(graph)$color <- edge_type_colors[E(graph)$edge_type]
par(mfrow=c(1,1), mar=c(0,0,0,0))
plot(graph, vertex.size = 20, edge.width = 1, edge.color = E(graph)$color)
```

## Sampling Procedure & Justification

Running the entire cleaned and processed dataset post-data cleaning, PCA, and feature extraction would be very resource intensive and not feasible in a local RStudio environment to generate visualizations of the graph. Therefore, we propose a sampling approach that draws a representative sample of the dataset's entire remaining feature space. The methodology for sampling the dataset is explained below.

Due to the lengthy computation time of our edge-generating function, we have chosen to use samples of our full data to analyze the network. A one-thousand node sample takes approximately one minute to generate edges, a two-thousand sample take around ten minutes. This increase in time makes it unfeasible to use larger samples, let alone the entire data set of around 700 thousand nodes. Therefore, we will keep our sample sizes in the 1000 to 2000 range.

The percentage of fraudulent nodes in the full data set is approximately 1%. To ensure this proportion is consistent in our sample we use stratified sampling. Stratified sampling samples 1% of the data from a strata of only fraudulent nodes and the other 99% of the data from a strata of only the non-fraudulent nodes.

Prior to using a sample in our project, we ensure that the sample is representative of the entire data set by applying the Chi-Squared test to our sample. The Chi-Squared test will determine if there is a significant difference between the values in the columns of the sample and in the full data set. The Chi-Squared test generates p-values for each column in a sample. A p-value of less than 0.05 will signal a significant difference between the sample and the full data set for that particular column. By conducting the Chi-Squared test on a given sample we ensure that it is sufficiently representative of the entire data set.

```{r}
# Percentage of fraudulent nodes in the data frame:
# fraud_percentage = ((bankfraud_data$fraud_bool == 1)/nrow(bankfraud_data))*100
# fraud_percentage
# str(data_sample)
# str(binned_bankfraud_data)

# Factor data for chi_Squared test:
data_sample$payment_type = as.factor(data_sample$payment_type)
data_sample$bank_branch_count_8w = as.factor(data_sample$bank_branch_count_8w)
data_sample$zip_count_4w = as.factor(data_sample$zip_count_4w)
data_sample$name_email_similarity = as.factor(data_sample$name_email_similarity)
data_sample$bank_months_count = as.factor(data_sample$bank_months_count)
data_sample$housing_status = as.factor(data_sample$housing_status)
data_sample$velocity_6h = as.factor(data_sample$velocity_6h)
data_sample$current_address_months_count = as.factor(data_sample$current_address_months_count)

binned_bankfraud_data$payment_type = as.factor(binned_bankfraud_data$payment_type)
binned_bankfraud_data$bank_branch_count_8w = as.factor(binned_bankfraud_data$bank_branch_count_8w)
binned_bankfraud_data$zip_count_4w = as.factor(binned_bankfraud_data$zip_count_4w)
binned_bankfraud_data$name_email_similarity = as.factor(binned_bankfraud_data$name_email_similarity)
binned_bankfraud_data$bank_months_count = as.factor(binned_bankfraud_data$bank_months_count)
binned_bankfraud_data$housing_status = as.factor(binned_bankfraud_data$housing_status)
binned_bankfraud_data$velocity_6h = as.factor(binned_bankfraud_data$velocity_6h)
binned_bankfraud_data$current_address_months_count = as.factor(binned_bankfraud_data$current_address_months_count)

# Chi-Squared test:
chi_squared_results = list()

for (col in names(data_sample)[-c(1,3:6,13)]) {
  population_counts = table(binned_bankfraud_data[[col]])
  sample_counts = table(data_sample[[col]])
  
  all_levels = names(population_counts)
  sample_counts = sample_counts[all_levels]
  
  sample_counts[is.na(sample_counts)] = 0
  
  chi_test = chisq.test(x = sample_counts, p = population_counts/sum(population_counts))
  
  chi_squared_results[[col]] = chi_test$p.value
}

chi_squared_df = data.frame(Column = names(chi_squared_results), P_Value = unlist(chi_squared_results))

print(chi_squared_df)
```

## Data Description

The dataset post-processing has been reduced to the following columns that will be considered in the following research questions:

1.  node_id - The ID of the node

2.  payment_type - The different types of credit payment plans available

3.  keep_alive_session - Binary variable to represent if a user is still browsing post logging out of the bank's website

4.  foreign_request - If the bank account request came from a different country than the bank's country

5.  email_is_free - If the user's email is a business or non-business email

6.  fraud_bool - Fraudulent status of the bank account request

7.  bank_branch_count_8w - Number of bank account requests in the last 2 months for the branch that the request went to

8.  zip_count_4w - Number of bank account applications within the same zip code as a particular application

9.  name_email_similarity - Similarity of user's name to their email address

10. bank_months_count - Number of months a user has held a previous bank account for

11. housing_status - Type of housing a user is living in

12. velocity_6h - Number of bank account requests created in the last 6 hours

13. phone_home_valid - If a user's provided phone number is valid or not

14. current_address_months_count - How long in months a user has lived at their current address

## Research Question 1: Which were the key fraudulent players within the network?

This research question aims to determine the most important fraudulent players within the sample taken of the network. Treating each bank account request as a node (row in the dataset), the general process that will be followed will be to observe the distribution of values for each of the following centrality measures, and set a threshold for defining a node as highly influential or not, and make a recommendation on which nodes should be further analyzed through domain expertise, and other ground truth information to determine fraud rings and/or individuals that were involved in defrauding the bank either directly or indirectly.

The overarching hypothesis of this project is that the links between the nodes due to the similarities in the attributes of their bank account requests could possibly suggest that some nodes were involved in defrauding the bank in groups, or may have been part of the crime itself in isolation, or were involved in some manner in defrauding the bank, and the research questions aim to figure out those connections between the nodes, and whether it makes practical sense to flag the identified nodes as suspicious.

```{r}
bankfraud_data
```

The following metrics will be used in identifying the influential fraudulent nodes in the network:

1.  Eigenvector centrality

2.  Betweenness centrality

Below is the sample creation and plotting process, the sample drawn is random, and is representative of the dataset. The process below can be applied to the entire dataset (resource-permitting), but since we do not have the resources to generate the entire graph, we will be working with samples in all of the research questions.

```{r}
# Creating sample
sample_size = 50
data_sample_q1 = sample_n(binned_bankfraud_data, sample_size)
str(data_sample_q1)

# Creating edge list
edges_list <- expand.grid(row_id_1 = seq_len(nrow(data_sample_q1)), row_id_2 = seq_len(nrow(data_sample_q1))) %>%
  filter(row_id_1 < row_id_2) %>% 
  rowwise() %>%
  mutate(
    edge_type = list(names(data_sample_q1)[-c(1,3:6,13)][
      sapply(names(data_sample_q1)[-c(1,3:6,13)], function(col) {
        data_sample_q1[[col]][row_id_1] == data_sample_q1[[col]][row_id_2]
      })
    ])
  ) %>%
  filter(length(edge_type) > 0) %>%
  unnest(edge_type) %>%
  ungroup() %>%
  mutate(
    node_id_1 = data_sample_q1$node_id[row_id_1],
    node_id_2 = data_sample_q1$node_id[row_id_2]
  ) %>%
  select(node_id_1, node_id_2, edge_type)
print(edges_list)
nrow(edges_list)
unique(edges_list$edge_type)

# Plotting the Graph
graph_rq1 <- graph_from_data_frame(d = edges_list, vertices = data_sample_q1, directed = FALSE)
edge_type_colors <- c("payment_type" = "green", "bank_branch_count_8w" = "blue", "name_email_similarity" = "yellow",
                       "zip_count_4w" = "cyan", "velocity_6h" = "blueviolet", "current_address_months_count" = "gold4",
                       "bank_months_count" = "darkseagreen1", "housing_status" = "darkorange1", "binary_combination_value" = "black")
E(graph_rq1)$color <- edge_type_colors[E(graph_rq1)$edge_type]
par(mfrow=c(1,1), mar=c(0,0,0,0))
plot(graph_rq1, vertex.size = 20, edge.width = 1, edge.color = E(graph)$color)
```

Now, we will construct the columns for the different centrality metrics stated above, and interpret the metrics in the context of bank fraud detection. We will start with eigenvector centrality. All the nodes within the sample are considered when determining the nodes that are influential based on the eigenvector centrality scores of the nodes.

```{r}
data_sample_q1
```

```{r}
# Computing the eigenvector centrality scores and adding them to the data sample
eigencentralities <- eigen_centrality(graph_rq1)
data_sample_q1[, 16] <- eigencentralities$vector
colnames(data_sample_q1)[16] <- "eigen_vector_centrality_score"

# Ordering the nodes based on descending eigenvector centrality scores to determine the nodes with the highest relative eigenvector centrality scores
data_sample_q1_ordered_ev <- arrange(data_sample_q1, desc(data_sample_q1$`eigen_vector_centrality_score`))

# Extracting the records in the top 25 percentiles of the eigenvector centrality scores to pick out the most important nodes from the sample
eigenvector_centrality_threshold <- quantile(data_sample_q1_ordered_ev$eigen_vector_centrality_score, 0.75)
most_influential_nodes_by_ev_centrality <- data_sample_q1_ordered_ev[data_sample_q1_ordered_ev$eigen_vector_centrality_score > eigenvector_centrality_threshold, ]
most_influential_nodes_by_ev_centrality
```

Influential/important nodes in the context of bank account fraud detection are nodes that are possibly committing bank account fraud, and/or could be in a group that is defrauding the bank.

The threshold of the top 25 percentiles was set in order to detect only the most important nodes with a high value for the eigenvector centrality, and which may not themselves be fraudulent but can be flagged as suspicious based on the quality of their connections within the network, and could possibly be collaborating with other nodes in the network to defraud the bank. Eigenvector centrality scores in the context of bank account fraud detection tell us that the higher the eigenvector centrality score for a node, the higher the number of important nodes that it is connected to.

The nodes that appear above the threshold for the calculated metrics can be determined with confidence as suspicious, but the others can be further investigated due to their ties to various nodes that were flagged.

13 nodes were flagged as suspicious from this sample based on them exceeding the threshold of the top 25 percentiles for the eigenvector centrality score, and in the context of bank fraud, they seem to have connections to node(s) that have been caught committing bank fraud or may have been caught committing bank fraud themselves.The IDs of the nodes that were flagged based on their high eigenvector centrality were as follows:

```{r}
nodes_flagged_ids_eigenvector <- most_influential_nodes_by_ev_centrality[, 1]
print(as.list(nodes_flagged_ids_eigenvector))
nodes_flagged_ids_eigenvector <- as.vector(nodes_flagged_ids_eigenvector)
```

All the columns for the nodes that were flagged suspicious can be further investigated by domain experts to make the best judgement on whether the flagged nodes were participating in bank fraud or were part of any fraud rings, or whether some of the nodes flagged were false positives.

The main advantage of using eigenvector centrality as a metric to flag nodes as suspicious is that eigenvector centrality takes into account both the quantity and the quality of the connections, and the main disadvantage of Eigenvector centrality is that large hubs can influence centrality scores of other nodes, and could ruin the quality of the centrality scores assigned.

Now, we will calculate the betweenness centrality scores for the above drawn sample of nodes, and flag suspicious nodes in a similar manner as performed above to identify potentially influential nodes in the context of committing bank account fraud.

```{r}
# Computing the betweenness centrality scores of the nodes in the sample
betweenness_centrality_scores <- betweenness(graph_rq1)
data_sample_q1[, 17] <- betweenness_centrality_scores
colnames(data_sample_q1)[17] <- "betweenness_centrality_score"

# Ordering the nodes based on descending betweenness centrality scores to determine the nodes with the highest relative betweenness centrality scores
data_sample_q1_ordered_betweenness <- arrange(data_sample_q1, desc(data_sample_q1$betweenness_centrality_score))

# Extracting the records in the top 25 percentiles of the betweenness centrality scores to pick out the most important nodes from the sample
betweenness_centrality_threshold <- quantile(data_sample_q1_ordered_betweenness$betweenness_centrality_score, 0.75)
most_influential_nodes_by_betweenness_centrality <- data_sample_q1_ordered_betweenness[data_sample_q1_ordered_betweenness$betweenness_centrality_score > betweenness_centrality_threshold, ]
most_influential_nodes_by_betweenness_centrality
```

Nodes with high betweenness centrality scores are nodes that tend to be the middlemen for information flow, and in the context of bank fraud, these nodes can be vital to the fraud rings as middlemen for information flow about defrauding the bank. Removing these nodes from the network could collapse the entire fraud ring, and it would be in the bank's best interest to flag these nodes, and further investigate the attributes of these nodes to deem them as being part of a fraudulent group or being fraudulent.

The threshold of the top 25 percentiles was set in order to detect only the most important nodes with a high value for the betweenness centrality, and which may not themselves be fraudulent but can be flagged as suspicious based on their ability to act as middlemen for information flow within the network, and could possibly be collaborating with other nodes in the network to defraud the bank or be the fraud ring leaders themselves due to them being on the shortest paths to many nodes within the network.

13 nodes were flagged using the betweenness centrality approach to detecting bank account fraud and can be further investigated by domain experts to identify whether the nodes flagged were part of fraud rings or were fraudulent. The IDs of the nodes that were flagged based on their high betweenness centrality were as follows:

```{r}
nodes_flagged_ids_betweenness <- most_influential_nodes_by_betweenness_centrality[, 1]
print(as.list(nodes_flagged_ids_betweenness))
nodes_flagged_ids_betweenness <- as.vector(nodes_flagged_ids_betweenness)
```

The main advantage of using betweenness centrality as a metric to flag nodes as suspicious is that betweenness centrality identifies the nodes that act as middlemen to the most number of nodes, and if removed can cause the information flow to be disrupted severely. The main disadvantage of using betweenness centrality is that it can be computationally expensive due to the metric needing to calculate a lot of shortest paths.

The following metrics are not suitable for identifying the influential fraudulent nodes in the network:

1.  Katz centrality

As this graph was a heavily connected undirected multigraph, there are barely any if not 0 nodes with an indegree of 0, and the advantage of using Katz centrality is that it accommodates for nodes with an indegree of 0 by providing them with "free" centrality scores in addition to the computed centrality scores.

2.  Closeness centrality

In the context of how we have defined our graph as containing links between users based on the similarity of their bank account requests, closeness centrality does not make much sense as a centrality metric due to it being about the speed at which information can reach other nodes from a starting node, and not about whether the node is accessible to many nodes like in the case of betweenness centrality, therefore, it is not appropriate in our context.

3.  Degree centrality

In the context of how we have defined our graph as containing links between users based on the similarity of their bank account requests, degree centrality is not an appropriate centrality metric due to it focusing purely on the number of nodes a particular node is connected to, and is not concerned about the centrality of the nodes that a particular node is connected to, which may lead to incorrectly deeming a node as a suspicious, when it may not be.

4.  PageRank centrality

In the context of our research question pagerank centrality does not seem to provide much more information than eigenvector centrality in an undirected network.

Below is a venn diagram of the nodes that were flagged as suspicious by various metrics, and which nodes are deemed by more than 1 centrality metric as being suspicious which can be used in further domain-specific analysis to determine whether the nodes are linked to fradulent entities or whose request may be frauduelent:

```{r}
#install.packages("VennDiagram")
library(grid)
library(VennDiagram)
venndiagram <- venn.diagram(x = list(nodes_flagged_ids_betweenness$node_id, nodes_flagged_ids_eigenvector$node_id), category.names = c("Betweenness Centrality", "Eigenvector Centrality"), filename = NULL, main = "Venn Diagram of the number of Overlapping Flagged Nodes from the different centrality metrics", output = TRUE, fill = c("red", "green"), alpha = 0.5, cex = 0.75, cat.cex = 0.75)
grid.newpage()
grid.draw(venndiagram)
```

The red colored circle represents the number of Node IDs of the high betweenness centrality flagged nodes, and the green colored circle represents the number of Node IDs of the high eigenvector centrality flagged nodes.. The nodes that were flagged as having high values for both centrality metrics are the nodes that need to be investigated further.

```{r}
most_suspicious_nodes_by_all_metrics <- intersect(nodes_flagged_ids_betweenness$node_id, nodes_flagged_ids_eigenvector$node_id)
print(most_suspicious_nodes_by_all_metrics)
```

The above 6 nodes would be the best to investigate further if investigating all 39 nodes flagged as suspicious is infeasible.

## Research Question 2: What was the average profile of a fraudulent customer?

```{r}

```

## Research Question 3: Were there any specific fraudulent groups within the network that could be collaborating to defraud the bank? And if so, what were their characteristics?

This research question aims to find clusters of nodes within the entire network, that could potentially be fraud rings based on the attributes of the nodes. Clusters that are majorly the same throughout different results from different network metrics could be potential fraud rings, and will be determined using centrality metrics such as:

1.  Network density

2.  Local clustering coefficient

3.  Modularity

4.  Graph laplacian

5.  Edge betweenness

6.  Global clustering coefficient

7.  K-cores

```{r}
str(bankfraud_data)

# Checking ranges:
range(bankfraud_data$payment_type)
range(bankfraud_data$bank_months_count)
range(bankfraud_data$bank_branch_count_8w)
range(bankfraud_data$zip_count_4w)
range(bankfraud_data$name_email_similarity)
range(bankfraud_data$bank_months_count)
range(bankfraud_data$housing_status)
range(bankfraud_data$velocity_6h)
range(bankfraud_data$current_address_months_count)

# Adding node_id column to identify vertices:
bankfraud_data$node_id = seq.int(nrow(bankfraud_data))
bankfraud_data = bankfraud_data %>% relocate(node_id)

# Creating Bins for bank_branch_count_8w, zip_count_4w, name_email_similarity, bank_months_count, velocity_6h, current_address_months_count:
bin_count = 200
binned_bankfraud_data = bankfraud_data
cols_to_bin = c("bank_branch_count_8w", "zip_count_4w", "name_email_similarity", "bank_months_count", "velocity_6h", "current_address_months_count")
binned_bankfraud_data[cols_to_bin] = data.frame(lapply(binned_bankfraud_data[cols_to_bin], function(x) cut(x, breaks = bin_count, labels=FALSE)))
str(binned_bankfraud_data)

# Creating binary combination column:
binary_columns = c("keep_alive_session", "foreign_request", "email_is_free", "fraud_bool", "phone_home_valid")
binned_bankfraud_data$binary_combination_value = apply(binned_bankfraud_data[binary_columns], 1, function(x) {paste(as.character(x), collapse = "")})
str(binned_bankfraud_data)

# Creating sample:
sample_size = 1000
data_sample = sample_n(binned_bankfraud_data, sample_size)
str(data_sample)

# Creating edge list:
edges_list <- expand.grid(row_id_1 = seq_len(nrow(data_sample)), row_id_2 = seq_len(nrow(data_sample))) %>%
  filter(row_id_1 < row_id_2) %>%  # Remove duplicates and self-loops
  rowwise() %>%
  mutate(
    edge_type = list(names(data_sample)[-c(1,3:6,13)][
      sapply(names(data_sample)[-c(1,3:6,13)], function(col) {
        data_sample[[col]][row_id_1] == data_sample[[col]][row_id_2]
      })
    ])
  ) %>%
  filter(length(edge_type) > 0) %>%
  unnest(edge_type) %>%
  ungroup() %>%
  mutate(
    node_id_1 = data_sample$node_id[row_id_1],
    node_id_2 = data_sample$node_id[row_id_2]
  ) %>%
  select(node_id_1, node_id_2, edge_type)
print(edges_list)
nrow(edges_list)
unique(edges_list$edge_type)
# Plotting the Data:
graph <- graph_from_data_frame(d = edges_list, vertices = data_sample, directed = FALSE)
edge_type_colors <- c("payment_type" = "forestgreen", "bank_branch_count_8w" = "blue", "name_email_similarity" = "yellow",
                       "zip_count_4w" = "cyan", "velocity_6h" = "blueviolet", "current_address_months_count" = "gold4",
                       "bank_months_count" = "darkseagreen1", "housing_status" = "darkorange1", "binary_combination_value" = "black")
E(graph)$color <- edge_type_colors[E(graph)$edge_type]
par(mfrow=c(1,1), mar=c(0,0,0,0))
plot(graph,
     vertex.color = ifelse(V(graph)$fraud_bool, "red", "green"),
     vertex.size = 5,
     vertex.label = NA,
     edge.width = 1,
     edge.color = E(graph)$color
     )

# Filter for fraudulent accounts and calculate the averages for relevant columns
fraudulent_profile <- data_sample %>%
  filter(fraud_bool == 1) %>%     # Adjust `is_fraud` to match your column name
  summarise(across(where(is.numeric), mean, na.rm = TRUE))

# View the result
print(fraudulent_profile)

#Creates a Louvain community object
louv <- cluster_louvain(graph)

#
membership <- membership(louv)

#Add betweenness centrality as column 5
data_sample[,16] <- membership

#Renames column 16
colnames(data_sample)[16] <- c("louv")

#
degree_centrality <- degree(graph)

#Modularity
modularity(louv)

#Colours the nodes by community
V(graph)$community <- membership(louv)

#Plots the graph object
# plot(graph,
#      vertex.size = 5,
#      vertex.color = V(graph)$community,
#      vertex.label = NA,
#      edge.width = 1,
#      edge.color = E(graph)$color
#      )

## plot(graph, 
  #   vertex.color = ifelse(V(graph)$fraud_bool, "red", "green"), 
 #    vertex.size = 5, 
#     vertex.label = NA, 
#     edge.width = 1, 
 #    edge.color = E(graph)$color
 ##     )

# Group nodes by community
nodes_by_community <- split(data_sample, data_sample$louv)

# Count fraud nodes in each community
fraud_counts <- sapply(nodes_by_community, function(group) {
  sum(group$fraud_bool, na.rm = TRUE)  # Sum the `fraud_bool` column for each community
})

# View fraud counts per community
print(fraud_counts)



# Filter for fraudulent accounts and calculate the averages for relevant columns
com1 <- data_sample %>%
  filter(louv == 1) %>%     # Adjust to match your column name
  summarise(across(where(is.numeric), mean, na.rm = TRUE))

#
print(com1)



# Filter for fraudulent accounts and calculate the averages for relevant columns
com2 <- data_sample %>%
  filter(louv == 2) %>%     # Adjust to match your column name
  summarise(across(where(is.numeric), mean, na.rm = TRUE))

#
print(com2)



# Filter for fraudulent accounts and calculate the averages for relevant columns
com3 <- data_sample %>%
  filter(louv == 3) %>%     # Adjust to match your column name
  summarise(across(where(is.numeric), mean, na.rm = TRUE))

#
print(com3)



# Filter for fraudulent accounts and calculate the averages for relevant columns
com4 <- data_sample %>%
  filter(louv == 4) %>%     # Adjust to match your column name
  summarise(across(where(is.numeric), mean, na.rm = TRUE))

#
print(com4)

# Filter for fraudulent accounts and calculate the averages for relevant columns
fraudulent_profile2 <- bankfraud_data %>%
  filter(fraud_bool == 1) %>%     # Adjust to match your column name
  summarise(across(where(is.numeric), mean, na.rm = TRUE))

print(fraudulent_profile2)
```

## Research Question 4: What differences exist between fraudulent account applications and non-fraudulent account applications?

To examine this question, we compare the means of 6 different metrics for both fraudulent and legitimate nodes within a sample. Samples of 1000 nodes are used and mean metrics are recorded for 10 separate samples. The mean metrics of the 10 samples are then aggregated to further remove sampling bias. The metrics to be compared are degree centrality, eigenvector centrality, jaccard similarity, local clustering coefficient, betweenness centrality and closeness centrality.

```{r}
#graph creation:
bin_count = 100
binned_bankfraud_data = bankfraud_data

cols_to_bin = c("bank_branch_count_8w", "zip_count_4w", "name_email_similarity", "bank_months_count", "velocity_6h", "current_address_months_count")

binned_bankfraud_data[cols_to_bin] = data.frame(lapply(binned_bankfraud_data[cols_to_bin], function(x) cut(x, breaks = bin_count, labels=FALSE)))

binary_columns = c("keep_alive_session", "foreign_request", "email_is_free", "phone_home_valid")

binned_bankfraud_data$binary_combination_value = apply(binned_bankfraud_data[binary_columns], 1, function(x) {paste(as.character(x), collapse = "")})

sample_size = 1000
sample_size_fraud = sample_size*0.01
sample_size_legit = sample_size*0.99

sample_fraud = binned_bankfraud_data %>% filter(fraud_bool == 1) %>% slice_sample(n = sample_size_fraud)
sample_legit = binned_bankfraud_data %>% filter(fraud_bool == 0) %>% slice_sample(n = sample_size_legit)

data_sample = bind_rows(sample_fraud, sample_legit)

edges_list = create_edges(data_sample)
graph = graph_from_data_frame(d = edges_list, vertices = data_sample, directed = FALSE)

V(graph)
legit_nodes = V(graph)[fraud_bool == 0]
fraud_nodes = V(graph)[fraud_bool == 1]

#mean degree centrality
mean_legit_degrees = mean(degree(graph, v = legit_nodes))
mean_fraud_degrees = mean(degree(graph, v = fraud_nodes))
mean_legit_degrees
mean_fraud_degrees

#mean jaccard similarity
jaccard = similarity(graph, method = "jaccard")
jaccard[lower.tri(jaccard, diag = TRUE)] = NA # removing diagonal values and duplicate values in the lower triangle
legit_jaccard = jaccard[as.integer(legit_nodes), ] #isolating legit nodes
fraud_jaccard = jaccard[as.integer(fraud_nodes), ] #isolating fraudulent nodes

mean(legit_jaccard, na.rm = TRUE)
mean(fraud_jaccard, na.rm = TRUE)

#mean eigenvector centrality
eigenvector = eigen_centrality(graph, directed=FALSE)$vector
legit_eigenvector = eigenvector[legit_nodes]
fraud_eigenvector = eigenvector[fraud_nodes]

mean(legit_eigenvector)
mean(fraud_eigenvector)

#mean closeness centrality:
closeness_values = closeness(graph, normalized = TRUE)
legit_closeness = closeness_values[legit_nodes]
fraud_closeness = closeness_values[fraud_nodes]

mean(legit_closeness)
mean(fraud_closeness)

#mean local clustering coefficient:
clustering = transitivity(graph, type = "local", isolates = "zero")

legit_clustering = clustering[legit_nodes]
fraud_clustering = clustering[fraud_nodes]

mean(legit_clustering)
mean(fraud_clustering)

#betweenness centrality:
betweennes_values = betweenness(graph, directed=FALSE)
legit_betweennes = betweennes_values[legit_nodes]
fraud_betweennes = betweennes_values[fraud_nodes]

mean(legit_betweennes)
mean(fraud_betweennes)
```

QUARTO RENDER

## Interpretation Summary

## Conclusion
